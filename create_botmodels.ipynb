{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mytas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from time import time\n",
    "import pymorphy2\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuruBot:\n",
    "    def __init__(self,\n",
    "                 model_path, \n",
    "                 data_paths, \n",
    "                 morph, \n",
    "                 botfile = 'gurubot',\n",
    "                 pos_map={\n",
    "                    'NOUN': '_NOUN',\n",
    "                    'VERB': '_VERB', \n",
    "                    'INFN': '_VERB',\n",
    "                    'GRND': '_VERB', \n",
    "                    'PRTF': '_VERB', \n",
    "                    'PRTS': '_VERB',\n",
    "                    'ADJF': '_ADJ', \n",
    "                    'ADJS': '_ADJ',\n",
    "                    'ADVB': '_ADV',\n",
    "                    'PRED': '_ADP',\n",
    "                    'NUMR': '_NUM'\n",
    "                }, start = [\n",
    "                    '–£—á–∏—Ç–µ–ª—å', \n",
    "                    '–ú–∞—Å—Ç–µ—Ä', \n",
    "                    '–ú—É–¥—Ä–µ—Ü', \n",
    "                    '–§–∏–ª–æ—Å–æ—Ñ'\n",
    "                ], middle = [\n",
    "                    ' ', \n",
    "                    ' —Å —É–ª—ã–±–∫–æ–π ', \n",
    "                    ' ', \n",
    "                    ', –ø–æ–¥—É–º–∞–≤, ', \n",
    "                    ', –ø–æ–º–æ–ª—á–∞–≤, ', \n",
    "                    ' —Ç–∏—Ö–æ ', \n",
    "                    ' —É–≤–µ—Ä–µ–Ω–æ ', \n",
    "                    ' ', \n",
    "                    ' –ø–æ—É—á–∏—Ç–µ–ª—å–Ω–æ '\n",
    "                ], end = [\n",
    "                    '–æ—Ç–≤–µ—á–∞–µ—Ç', \n",
    "                    '–ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç', \n",
    "                    '–≥–æ–≤–æ—Ä–∏—Ç', \n",
    "                    '–æ–±—ä—è—Å–Ω—è–µ—Ç'\n",
    "                ], smiles = [\n",
    "                     '‚ò∫', '‚òª', '‚úå', '‚òπ', '‚ô°', '‚ô•', \n",
    "                     '‚ù§', '‚öò', '‚ùÄ', '‚ùÉ', '‚ùÅ', '‚úº', \n",
    "                     '‚òÄ', '‚úå', '‚ô´', '‚ô™', '‚òÉ', '‚ùÑ', \n",
    "                     '‚ùÖ', '‚ùÜ', '‚òï', '‚òÇ', '‚òÖ', 'üíã', \n",
    "                     '‚óï‚Äø‚óï', 'ÔΩ°‚óï‚Äø‚óïÔΩ°', 'ÔΩ°‚óï‚Äø‚Äø‚óïÔΩ°', '^ÃÆ^',\n",
    "                     '(‚óï‚Äø‚óï)', '(ÔΩ°‚óï‚Äø‚óïÔΩ°)', '(ÔΩ°‚óï‚Äø‚Äø‚óïÔΩ°)', \n",
    "                     '(^ÃÆ^)', ' ò‚Äø ò', '‡≤†_‡≤†', '‡≤†‚Äø‡≤†', '( ò‚Äø ò)',\n",
    "                     '(‡≤†_‡≤†)', '(‡≤†‚Äø‡≤†)', '‚ô•‚Äø‚ô•', '‚äôÔπè‚äô', \n",
    "                     '(¬¨_¬¨)', '‚óï‚Äø‚Üº', '(¬¨‚Äø¬¨)', '‚óî ‚å£ ‚óî', \n",
    "                     '(ÔΩ°‚óï‚Äø‚Äø‚óïÔΩ°)', '¬Ø\\_(„ÉÑ)_/¬Ø', '(¬∞ Õú ñ ¬∞)', \n",
    "                     '¬Ø\\(¬∞_o)/¬Ø', '(Ô∏∫Ô∏πÔ∏∫)'\n",
    "                 ]):\n",
    "        self.model = KeyedVectors.load_word2vec_format(model_path, encoding='utf-8')\n",
    "        self.morph = morph\n",
    "        self.botfile = '_'.join([botfile, model_path.split('.')[0], str(int(time()))])\n",
    "        self.pos_map = pos_map\n",
    "        self.library = self.build_library(data_paths)\n",
    "        self.intros = [s+m+e+':' for s in start for m in middle for e in end]\n",
    "        self.smiles = smiles + ['']*len(smiles)*6\n",
    "        self.export()\n",
    "    \n",
    "    \n",
    "    def load_data(self, data_paths):\n",
    "        data = []\n",
    "        for path in data_paths:\n",
    "            with open(path, encoding='utf-8') as f:\n",
    "                data += f.read().split('\\n')    \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def export(self, path='botfiles/', fname=''):\n",
    "        fname = fname if fname else self.botfile\n",
    "        with open(path+fname+'.pkl', 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        \n",
    "        \n",
    "    def cleanse(self, string):\n",
    "        rgxp = '[\\`\\)\\(\\|¬©~^<>/\\'\\\"\\¬´‚Ññ#$&\\*.,;=+?!\\‚Äî_@:\\]\\[%\\{\\}0-9A-Za-z\\\\n]'\n",
    "        return re.sub(' +', ' ', re.sub(rgxp, ' ', string.lower()))\n",
    "\n",
    "    \n",
    "    def lemmatize(self, string, protected=[]):\n",
    "        return [self.morph.parse(word)[0].normal_form \\\n",
    "                for word in word_tokenize(self.cleanse(string))]\n",
    "\n",
    "\n",
    "    def map_pos(self, pos):\n",
    "        return self.pos_map[pos] if pos in self.pos_map else \"_X\"\n",
    "\n",
    "\n",
    "    def make_bag(self, string):\n",
    "        pos_words = [word + self.map_pos(str(self.morph.parse(word)[0].tag.POS)) \\\n",
    "                     for word in self.lemmatize(string)]\n",
    "        return [w for w in pos_words if w in self.model.vocab]\n",
    "    \n",
    "    \n",
    "    def build_library(self, data_paths):\n",
    "        return [(self.make_bag(string), string) \\\n",
    "                for string in self.load_data(data_paths)]\n",
    "\n",
    "\n",
    "    def similarity(self, bag1, bag2, rand_coef=0.01):\n",
    "        try: \n",
    "            res = sum([self.model.similarity(i, j) for i in bag1 for j in bag2])\n",
    "            res /= (len(bag1) * len(bag2))\n",
    "        except:\n",
    "            res = 0\n",
    "        return res + random.uniform(0, rand_coef)\n",
    "\n",
    "\n",
    "    def find_reply(self, inp):\n",
    "        similar_answers = [(self.similarity(inp, answer[0]), answer[1])\\\n",
    "                           for answer in self.library]\n",
    "        similar_answers.sort(key=lambda x:x[0], reverse=True)\n",
    "        return similar_answers[0][1]\n",
    "\n",
    "\n",
    "    def make_surface(self, reply):\n",
    "        intro = random.choice(self.intros) + \" \" if self.intros else \"\"\n",
    "        phrase = intro + reply[0].lower() + reply[1:] if intro else reply\n",
    "        return phrase + ' ' + random.choice(self.smiles)\n",
    "\n",
    "\n",
    "    def answer(self, inp):\n",
    "        inp_bag = self.make_bag(inp)\n",
    "        return self.make_surface(self.find_reply(inp_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurfaceRealizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def make_surface(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-19 22:43:53,212 : INFO : Loading dictionaries from c:\\users\\mytas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2018-06-19 22:43:53,321 : INFO : format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n",
      "2018-06-19 22:43:53,325 : INFO : loading projection weights from ruscorpora_upos_skipgram_300_5_2018.vec.gz\n",
      "2018-06-19 22:45:32,087 : INFO : loaded (195071, 300) matrix from ruscorpora_upos_skipgram_300_5_2018.vec.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "guru = GuruBot(\n",
    "    model_path = 'ruscorpora_upos_skipgram_300_5_2018.vec.gz', \n",
    "    data_paths = [\n",
    "        'twen.txt', \n",
    "        'proverbs.txt', \n",
    "        'zavets.txt', \n",
    "        'confuc.txt'\n",
    "    ],\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...: –ü—Ä–∏–≤–µ—Ç, –¥—Ä—É–≥\n",
      "–£—á–∏—Ç–µ–ª—å —É–≤–µ—Ä–µ–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç: –¥—Ä—É–∑—å—è –Ω–∞—à–∏—Ö –¥—Ä—É–∑–µ–π - –Ω–∞—à–∏ –¥—Ä—É–∑—å—è ‚òª\n",
      "...: –¢—ã –º–Ω–µ –Ω—Ä–∞–≤–∏—à—å—Å—è\n",
      "–ú–∞—Å—Ç–µ—Ä –æ–±—ä—è—Å–Ω—è–µ—Ç: —á—Ç–æ –Ω—Ä–∞–≤–∏—Ç—Å—è, —Ç–æ –∏ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ. \n",
      "...: –°–∫–∞–∂–∏ –º–Ω–µ, –∫–æ–≥–¥–∞ —É–∂–µ –±—É–¥–µ—Ç –æ–±–µ–¥?\n",
      "–ú—É–¥—Ä–µ—Ü —Å —É–ª—ã–±–∫–æ–π –≥–æ–≤–æ—Ä–∏—Ç: –∏ —Å–∫–∞–∂–µ—à—å - –ø–ª–æ—Ö–æ, –∏ –Ω–µ —Å–∫–∞–∂–µ—à—å - –ø–ª–æ—Ö–æ. \n",
      "...: –î–∞ –ø–æ—á–µ–º—É –∂–µ —Ç—ã —Ç–∞–∫ –¥—É–º–∞–µ—à—å?\n",
      "–ú—É–¥—Ä–µ—Ü –æ–±—ä—è—Å–Ω—è–µ—Ç: —á—Ç–æ –¥—É–º–∞–µ—Ç, —Ç–æ –∏ –≥–æ–≤–æ—Ä–∏—Ç. \n",
      "...: –¢—ã –¥—É—Ä–∞–∫\n",
      "–§–∏–ª–æ—Å–æ—Ñ, –ø–æ–º–æ–ª—á–∞–≤, –≥–æ–≤–æ—Ä–∏—Ç: –ø—Ä–∏ –¥–µ–Ω—å–≥–∞—Ö-—Ç–æ –∏ –¥—É—Ä–∞–∫ —É–º–Ω—ã–π.  ÔΩ°‚óï‚Äø‚Äø‚óïÔΩ°\n",
      "...: –ê —É —Ç–µ–±—è —á—Ç–æ, –¥–µ–Ω–µ–≥ –º–Ω–æ–≥–æ?\n",
      "–ú—É–¥—Ä–µ—Ü, –ø–æ–º–æ–ª—á–∞–≤, –æ—Ç–≤–µ—á–∞–µ—Ç: —Å –¥–µ–Ω—å–≥–∞–º–∏ –º–∏–ª, –±–µ–∑ –¥–µ–Ω–µ–≥ –ø–æ—Å—Ç—ã–ª.  \n",
      "...: –í–æ—Ç –∏–º–µ–Ω–Ω–æ. –°–∏–¥–∏–º —Ü–µ–ª—ã–π –º–µ—Å—è—Ü –∏ –∂–¥–µ–º –∑–∞—Ä–ø–ª–∞—Ç—ã.\n",
      "–ú—É–¥—Ä–µ—Ü –æ–±—ä—è—Å–Ω—è–µ—Ç: –¥–æ–º–∞ —Å–∏–¥–µ—Ç—å - –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã—Å–∏–¥–µ—Ç—å. \n",
      "...: —Å—Ç–æ–ø\n"
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    i = input(\"...: \")\n",
    "    if i.lower() == '—Å—Ç–æ–ø': break \n",
    "    print(guru.answer(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-17 05:46:13,114 : INFO : Loading dictionaries from c:\\users\\mytas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2018-06-17 05:46:13,203 : INFO : format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n",
      "2018-06-17 05:46:13,208 : INFO : loading projection weights from araneum_upos_skipgram_300_2_2018.vec.gz\n",
      "2018-06-17 05:47:51,831 : INFO : loaded (196620, 300) matrix from araneum_upos_skipgram_300_2_2018.vec.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "guru_ar = GuruBot(\n",
    "    model_path = 'araneum_upos_skipgram_300_2_2018.vec.gz', \n",
    "    data_paths = [\n",
    "        'twen.txt', \n",
    "        'proverbs.txt', \n",
    "        'zavets.txt', \n",
    "        'confuc.txt'\n",
    "    ],\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...: —Å—Ç–æ–ø\n"
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    i = input(\"...: \")\n",
    "    if i.lower() == '—Å—Ç–æ–ø': break \n",
    "    print(guru.answer(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-19 22:46:58,859 : INFO : Loading dictionaries from c:\\users\\mytas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2018-06-19 22:46:59,824 : INFO : format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n"
     ]
    }
   ],
   "source": [
    "with open('botfiles\\gurubot_ruscorpora_upos_skipgram_300_5_2018_1529437532.pkl', 'rb') as f:\n",
    "    bott = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-22 02:42:50,843 : INFO : Loading dictionaries from c:\\users\\mytas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2018-06-22 02:42:50,996 : INFO : format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n",
      "2018-06-22 02:42:51,002 : INFO : loading projection weights from ruscorpora_upos_skipgram_300_5_2018.vec.gz\n",
      "2018-06-22 02:46:57,064 : INFO : loaded (195071, 300) matrix from ruscorpora_upos_skipgram_300_5_2018.vec.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hello = GuruBot(\n",
    "    model_path = 'ruscorpora_upos_skipgram_300_5_2018.vec.gz', \n",
    "    data_paths = [\n",
    "        'hellos.txt'\n",
    "    ],\n",
    "    morph = pymorphy2.MorphAnalyzer(),\n",
    "    botfile = 'hellobot',\n",
    "    start = []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...: –ü—Ä–∏–≤–µ—Ç!\n",
      "–ü—Ä–∏–≤–µ—Ç! ‚òï\n",
      "...: –ö–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç:\n",
      "–ú–µ–Ω—è –Ω–µ –∑–æ–≤—É—Ç, —è —Å–∞–º –ø—Ä–∏—Ö–æ–∂—É... –ü—Ä–æ—Å—Ç–∏—Ç–µ. \n",
      "...: –¢—ã –º–Ω–µ –Ω—Ä–∞–≤–∏—à—å—Å—è\n",
      "–†–∞–¥ –≤–∞—Å –≤–∏–¥–µ—Ç—å \n",
      "...: –î–∞–≤–∞–π –æ–±–Ω–∏–º–µ–º—Å—è\n",
      "–•–æ—Ä–æ—à–µ–≥–æ –≤–∞–º –¥–Ω—è! \n",
      "...: —Å—Ç–æ–ø\n"
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    i = input(\"...: \")\n",
    "    if i.lower() == '—Å—Ç–æ–ø': break \n",
    "    print(hello.answer(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
